# -*- coding: utf-8 -*-
"""Pan_Card_Detection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ShIDLfyLprvQEmsmr85MSYs_k4IWY8qr
"""

!pip install kaggle

#configurating the path of kaggle.json file
!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets download -d girinathrs211555/pan-card-datasets

# extrcing the compossed Dataset
from zipfile import ZipFile
dataset = '/content/pan-card-datasets.zip'

with ZipFile(dataset,'r') as zip:
  zip.extractall()
  print('The dataset is extracted')

"""# **Importing Dependencies**"""

import os
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import cv2
from google.colab.patches import cv2_imshow
from PIL import Image
from sklearn.model_selection import train_test_split

Pan_card_files = os.listdir('/content/PAN_CARD_DETECTION/Pan_Card')
print(Pan_card_files[0:5])

print(Pan_card_files[-5:])

Not_Pan_card_files = os.listdir('/content/PAN_CARD_DETECTION/Not_Pan_Card')
print(Not_Pan_card_files[0:5])

print(Not_Pan_card_files[-5:])

print('Number of with Pan_card_files:', len(Pan_card_files))
print('Number of without Not_Pan_card_files:', len(Not_Pan_card_files))

#create the labels

Pan_card_labels = [1]*5000

Not_Pan_card_labels = [0]*5000

# Checking wheather the labels are created as expected
print(Pan_card_labels[0:5])

print(Not_Pan_card_labels[0:5])

print(len(Pan_card_labels))
print(len(Not_Pan_card_labels))

# I am Concanating  the  two class as labels

labels = Pan_card_labels + Not_Pan_card_labels

print(len(labels))
print(labels[0:5])
print(labels[-5:])

# Convert images to numpy arrays

Pan_card_path = '/content/PAN_CARD_DETECTION/Pan_Card/'

data = []
for img_file in Pan_card_files:

  image = Image.open(Pan_card_path + img_file)
  image = image.resize((128,128))
  image = image.convert("RGB")
  image = np.array(image)
  data.append(image)


Not_Pan_card_path = '/content/PAN_CARD_DETECTION/Not_Pan_Card/'

for img_file in Not_Pan_card_files:

  image = Image.open(Not_Pan_card_path + img_file)
  image = image.resize((128,128))
  image = image.convert("RGB")
  image = np.array(image)
  data.append(image)

# Coverting image list and the label list to numpy arrays

X = np.array(data)
Y = np.array(labels)

type(X)

type(Y)

print(X.shape)
print(Y.shape)

print(Y)

"""# **Train Test Split**"""

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=2)

print(X.shape, X_train.shape, X_test.shape)

#Scaling the data

X_train_scaled = X_train/255

X_test_scaled = X_test/255

"""# **Building a Convolutional Neural Network(CNN)**"""

import tensorflow as tf
from tensorflow import keras

num_of_classes = 2

model = keras.Sequential()

model.add(keras.layers.Conv2D(1200, kernel_size=(3, 3), activation='relu', input_shape=(128, 128, 3)))
model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))

model.add(keras.layers.Conv2D(1500, kernel_size=(3, 3), activation='relu'))
model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))

model.add(keras.layers.Conv2D(1700, kernel_size=(3, 3), activation='relu'))
model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))

model.add(keras.layers.Conv2D(1800, kernel_size=(3, 3), activation='relu'))
model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))

model.add(keras.layers.Conv2D(2000, kernel_size=(3, 3), activation='relu'))
model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))

model.add(keras.layers.Flatten())

model.add(keras.layers.Dense(256, activation='relu'))
model.add(keras.layers.Dropout(0.5))

model.add(keras.layers.Dense(128, activation='relu'))
model.add(keras.layers.Dropout(0.5))

model.add(keras.layers.Dense(64, activation='relu'))
model.add(keras.layers.Dropout(0.5))

model.add(keras.layers.Dense(32, activation='relu'))
model.add(keras.layers.Dropout(0.5))

model.add(keras.layers.Dense(16, activation='relu'))
model.add(keras.layers.Dropout(0.5))

model.add(keras.layers.Dense(num_of_classes, activation='sigmoid'))

# Compile the neural network

model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['acc'])

#traing the neural network
history = model.fit(X_train_scaled, Y_train, validation_split=0.2, epochs=10)

loss, accuracy = model.evaluate(X_test_scaled, Y_test)
print('Test Accuracy=', accuracy)

h = history

#plot the loss value
plt.plot(h.history['loss'], label='train loss')
plt.plot(h.history['val_loss'], label='validation loss')
plt.legend()
plt.show()

#plot the accuracy value
plt.plot(h.history['acc'], label='train accuracy')
plt.plot(h.history['val_acc'], label='validation accuracy')
plt.legend()
plt.show()

input_image_path = input('Path of the image to be predicted: ')

input_image = cv2.imread(input_image_path)

cv2_imshow(input_image)

input_image_resized = cv2.resize(input_image, (128, 128))

input_image_scaled = input_image_resized/255

input_image_reshaped = np.reshape(input_image_scaled, [1,128,128,3])

input_prediction = model.predict(input_image_reshaped)

print(input_prediction)

input_pred_label = np.argmax(input_prediction)

print(input_pred_label)

if input_pred_label == 1:

  print('This is an Pan card')

else:

  print('This not an Pan card')

model.save('Pandulla.h5')